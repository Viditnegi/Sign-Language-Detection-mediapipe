{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e75ab7d-1995-43fb-af8c-32d434af0f9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import mediapipe as mp\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "\n",
    "\n",
    "\n",
    "classes_list = ['sad','friendly','trap','photo','map','bright','deaf','away','help','I','meet','my','name']\n",
    "num_of_videos = 30\n",
    "sequence_len = 20\n",
    "image_height = 240\n",
    "image_width = 320\n",
    "number_of_augmentations = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b596ff61-1b05-4535-8f98-4fb61994da67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# Define the augmentation pipeline\n",
    "transform = A.ReplayCompose([\n",
    "    # A.HorizontalFlip(p=0.5),\n",
    "    # A.RandomBrightnessContrast(p=0.2),\n",
    "    \n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(shift_limit=.2, scale_limit=(-0.3,-0.08), rotate_limit=10, p=0.8,border_mode=cv2.BORDER_CONSTANT),\n",
    "        A.ShiftScaleRotate(shift_limit=0, scale_limit=(0,0.15), rotate_limit=10, p=0.2,border_mode=cv2.BORDER_CONSTANT)\n",
    "    ],p=1.0)\n",
    "\n",
    " \n",
    "    # A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=.1),\n",
    "    # A.OneOf([\n",
    "    #     # A.CenterCrop(height=(image_height),width=(image_width),p=1.0),\n",
    "    #     A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.1, rotate_limit=0, p=1.0,border_mode=cv2.BORDER_CONSTANT)\n",
    "    # ],p=1),\n",
    "    # A.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.4, p=.6),\n",
    "    # A.Resize(height=IMAGE_HEIGHT, width=IMAGE_WIDTH,p=1.0)\n",
    "    # A.MotionBlur()\n",
    "    # A.Blur()\n",
    "    # A.MedianBlur()\n",
    "])\n",
    "\n",
    "def load_video(video_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    frames = []\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # frame = cv2.resize(frame,(image_width,image_height))\n",
    "        frames.append(frame)\n",
    "    cap.release()\n",
    "    return frames\n",
    "\n",
    "def save_video(frames, output_path):\n",
    "    height, width, _ = frames[0].shape\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, 30.0, (width, height))\n",
    "    for frame in frames:\n",
    "        out.write(frame)\n",
    "    out.release()\n",
    "\n",
    "\n",
    "def augment_video_frames(frames):\n",
    "    augmented_frames = []\n",
    "    \n",
    "    replay = None\n",
    "    for frame in frames:\n",
    "        # Apply the augmentations\n",
    "        if replay is None:\n",
    "            augmented = transform(image=frame)\n",
    "            replay = augmented['replay']\n",
    "        else:\n",
    "            augmented = A.ReplayCompose.replay(replay, image=frame)\n",
    "            \n",
    "        augmented_frames.append(augmented['image'])\n",
    "\n",
    "    return augmented_frames\n",
    "\n",
    "def process_video(video_path, output_path):\n",
    "    # Load video\n",
    "    video = load_video(video_path)\n",
    "\n",
    "    # Augment video\n",
    "    video_aug = augment_video_frames(video)\n",
    "\n",
    "    # Save video\n",
    "    save_video(video_aug, output_path)\n",
    "    \n",
    "    return np.array(video_aug)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd8123e3-d181-4edc-854e-0f629ea3db64",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "os.makedirs('datasets/augmented',exist_ok=True)\n",
    "\n",
    "for sign in classes_list:\n",
    "    counter = 0\n",
    "    os.makedirs(f'datasets/augmented/{sign}',exist_ok=True)\n",
    "    for video in os.listdir(f'datasets/original/{sign}'):\n",
    "        for aug in range(number_of_augmentations):\n",
    "            process_video(f'datasets/original/{sign}/{video}',f'datasets/augmented/{sign}/{counter}.mp4')\n",
    "            counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf3139f-11dc-4652-bdc0-0adef702d086",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee7b91cb-34e3-4a5a-985e-809055ceeca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82655683-2058-43f2-a712-32840eee983d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bb0659-9d3e-4824-a570-04091ed2ccd5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Sign_lang_2",
   "language": "python",
   "name": "sign_lang_2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
